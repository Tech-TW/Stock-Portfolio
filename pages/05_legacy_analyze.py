# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# æª”æ¡ˆï¼špages/03_legacy_analyze.py
# èªªæ˜ï¼šä¿ç•™ã€ŒèˆŠç‰ˆæœ¬ã€åŸºç¤åˆ†æé ï¼Œèˆ‡æ–°ç‰ˆä¸¦å­˜ä»¥åˆ©æ¯”è¼ƒï¼ˆASCII æª”åï¼Œé¿å…è¢«å¿½ç•¥ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

import streamlit as st
import pandas as pd
import numpy as np
from io import BytesIO
from datetime import datetime, timedelta
from collections import deque
from dateutil.relativedelta import relativedelta

import yfinance as yf

st.title("Analyze (Legacy)")

# å–å¾—ä¸Šå‚³è³‡æ–™
if "uploaded_df" not in st.session_state or st.session_state["uploaded_df"] is None:
    st.error("No data. Please upload at the **Upload** page first.")
    st.stop()

df_input: pd.DataFrame = st.session_state["uploaded_df"].copy()

# ========= é€šç”¨è¼”åŠ© =========
def make_excel_report(dfs: dict) -> bytes:
    buf = BytesIO()
    with pd.ExcelWriter(buf, engine="xlsxwriter") as writer:
        for name, _df in dfs.items():
            safe = str(name)[:31]
            (_df if isinstance(_df, pd.DataFrame) else pd.DataFrame(_df)).to_excel(
                writer, sheet_name=safe, index=False
            )
    buf.seek(0)
    return buf.read()

def determine_currency(ticker: str) -> str:
    t = str(ticker).upper()
    if t.endswith(".TW") or t.endswith(".TWO"): return "TWD"
    if t.isdigit() and len(t) == 4:            return "TWD"
    if t.endswith(".HK"):                       return "HKD"
    if t.endswith(".T"):                        return "JPY"
    if t.endswith(".L"):                        return "GBP"
    if t.endswith(".DE") or t.endswith(".F"):   return "EUR"
    if t.endswith(".TO"):                       return "CAD"
    if t.endswith(".AX"):                       return "AUD"
    return "USD"

def download_fx_history(currency: str, start_date: pd.Timestamp, end_date: pd.Timestamp) -> pd.DataFrame:
    if currency == "TWD":
        return pd.DataFrame({"æ—¥æœŸ":[start_date], "åŒ¯ç‡":[1.0], "å¹£åˆ¥":["TWD"]})
    try:
        fx_symbol = f"{currency}TWD=X"
        start_ex = start_date - timedelta(days=10)
        end_ex   = end_date + timedelta(days=10)
        fx = yf.download(fx_symbol, start=start_ex, end=end_ex, auto_adjust=True, progress=False)
        if fx.empty:
            return pd.DataFrame()
        fx_df = fx["Close"].reset_index()
        fx_df.columns = ["æ—¥æœŸ","åŒ¯ç‡"]
        fx_df["æ—¥æœŸ"]  = pd.to_datetime(fx_df["æ—¥æœŸ"]).dt.normalize()
        fx_df["å¹£åˆ¥"]  = currency
        return fx_df
    except Exception:
        return pd.DataFrame()

def get_fx_rate(date: pd.Timestamp, currency: str, fx_data_dict: dict) -> float:
    if currency == "TWD":
        return 1.0
    f = fx_data_dict.get(currency)
    if f is None or f.empty:
        return np.nan
    d0 = f.loc[(f["æ—¥æœŸ"] <= date), "æ—¥æœŸ"].max()
    if pd.isna(d0):
        d0 = f["æ—¥æœŸ"].min()
    rate = f.loc[f["æ—¥æœŸ"]==d0, "åŒ¯ç‡"]
    return float(rate.iloc[0]) if not rate.empty else np.nan

def get_latest_fx_rate(currency: str, fx_data_dict: dict) -> float:
    if currency == "TWD":
        return 1.0
    f = fx_data_dict.get(currency)
    if f is None or f.empty:
        try:
            sym = f"{currency}TWD=X"
            fx2 = yf.download(sym, period="5d", interval="1d", auto_adjust=True, progress=False)
            if not fx2.empty:
                return float(fx2["Close"].dropna().iloc[-1])
        except Exception:
            pass
        return np.nan
    f2 = f.dropna(subset=["åŒ¯ç‡"]).sort_values("æ—¥æœŸ", ascending=False)
    if f2.empty: return np.nan
    return float(f2.iloc[0]["åŒ¯ç‡"])

def download_stock_history(ticker: str, start_date: pd.Timestamp, end_date: pd.Timestamp) -> pd.DataFrame:
    try:
        start_ex = start_date - timedelta(days=10)
        end_ex   = end_date + timedelta(days=10)
        s = yf.download(ticker, start=start_ex, end=end_ex, auto_adjust=True, progress=False)
        if s.empty:
            return pd.DataFrame()
        sdf = s["Close"].reset_index()
        sdf.columns = ["æ—¥æœŸ","æ”¶ç›¤åƒ¹"]
        sdf["æ—¥æœŸ"] = pd.to_datetime(sdf["æ—¥æœŸ"]).dt.normalize()
        sdf["è‚¡ç¥¨ä»£è™Ÿ"] = ticker
        return sdf
    except Exception:
        return pd.DataFrame()

# ========= è‚¡ç¥¨åˆ†å‰²äº‹ä»¶è™•ç† =========
class StockEventProcessor:
    def __init__(self):
        self.events_data = {}

    def fetch_stock_events(self, ticker, start_date, end_date):
        events = {'splits': []}
        try:
            stock = yf.Ticker(ticker)
            actions = stock.actions.reset_index()
            if actions.empty:
                self.events_data[ticker] = events
                return events
            actions["Date"] = actions["Date"].dt.tz_localize(None)
            actions = actions[(actions["Date"]>=start_date)&(actions["Date"]<=end_date)].copy()
            if "Stock Splits" in actions.columns:
                s = actions[actions["Stock Splits"]>0][["Date","Stock Splits"]]
                if not s.empty:
                    s.columns = ["Date","Split_Ratio"]
                    for _,r in s.iterrows():
                        events["splits"].append({"date": r["Date"], "ratio": r["Split_Ratio"], "type": "split"})
        except Exception:
            pass
        self.events_data[ticker] = events
        return events

    def _calculate_shares_before_date(self, transaction_history: pd.DataFrame, ticker, target_date):
        t = transaction_history[
            (transaction_history["è‚¡ç¥¨ä»£è™Ÿ"]==ticker) &
            (transaction_history["æ—¥æœŸ"]<target_date)
        ]
        return max(0, float(t["è³¼è²·è‚¡æ•¸"].sum()))

    def apply_stock_split_with_timing(self, position_data, ticker, split_date, split_ratio, transaction_history=None):
        if ticker not in position_data:
            return None
        pos = position_data[ticker]
        original_shares = pos["shares"]
        original_avg_cost = pos["avg_cost_foreign"]

        if transaction_history is not None:
            shares_before = self._calculate_shares_before_date(transaction_history, ticker, split_date)
            if shares_before <= 0:
                return None
            add_shares = shares_before * (split_ratio - 1.0)
            pos["shares"] = original_shares + add_shares
            total_cost_foreign = original_avg_cost * original_shares
            if pos["shares"]>0:
                pos["avg_cost_foreign"] = total_cost_foreign / pos["shares"]
        else:
            pos["shares"] *= split_ratio
            pos["avg_cost_foreign"] /= split_ratio

        if pos["shares"]>0 and pos["avg_cost_foreign"]>0:
            pos["total_cost_twd"] = pos["avg_cost_foreign"] * pos["shares"] * pos.get("avg_exchange_rate", pos.get("avg_fx", 1.0))
        return {
            "ticker": ticker, "date": split_date, "event":"stock_split", "ratio":split_ratio,
            "original_shares": original_shares, "new_shares": pos["shares"],
            "original_avg_cost": original_avg_cost, "new_avg_cost": pos["avg_cost_foreign"]
        }

    def process_all_splits_for_ticker(self, position_data, ticker, transaction_history=None):
        if ticker not in self.events_data: return []
        splits = self.events_data[ticker].get("splits", [])
        if not splits: return []
        splits_sorted = sorted(splits, key=lambda x: x["date"])
        out=[]
        for sp in splits_sorted:
            r = self.apply_stock_split_with_timing(position_data, ticker, sp["date"], sp["ratio"], transaction_history)
            if r: out.append(r)
        return out

# ========= FIFOï¼ˆä¿®æ­£ç‰ˆï¼Œå«äº¤æ˜“æˆæœ¬ï¼‰ =========
def build_fifo_inventory_with_cost_fixed(df_trades, fx_data_dict, latest_prices=None):
    fifo_positions = {}
    fifo_realized_pnl_data = {}
    fifo_position_list = []

    for _, row in df_trades.sort_values("æ—¥æœŸ").iterrows():
        ticker = row["è‚¡ç¥¨ä»£è™Ÿ"]
        shares = float(row["è³¼è²·è‚¡æ•¸"])
        price  = float(row["è³¼è²·è‚¡åƒ¹"])
        fx     = float(row.get("æ›åŒ¯åŒ¯ç‡", 1.0))
        currency = row.get("å¹£åˆ¥", determine_currency(ticker))
        fee    = float(row.get("äº¤æ˜“æˆæœ¬", 0.0))

        fifo_positions.setdefault(ticker, deque())
        fifo_realized_pnl_data.setdefault(ticker, 0.0)

        if shares > 0:  # è²·
            actual_cost_ps = (price * shares + fee) / shares
            fifo_positions[ticker].append({
                "shares": shares,
                "price": actual_cost_ps,      # å«äº¤æ˜“æˆæœ¬
                "original_price": price,
                "fx": fx,
                "transaction_cost": fee,
                "currency": currency
            })
        else:          # è³£
            qty_to_sell = -shares
            realized = 0.0
            while qty_to_sell > 1e-12 and fifo_positions[ticker]:
                lot = fifo_positions[ticker][0]
                take = min(lot["shares"], qty_to_sell)
                per_share_fee = fee/qty_to_sell if qty_to_sell>0 else 0.0
                net_per_share = price - per_share_fee
                pnl_foreign = (net_per_share - lot["price"]) * take
                realized += pnl_foreign * lot["fx"]
                lot["shares"] -= take
                qty_to_sell   -= take
                if lot["shares"] <= 1e-12:
                    fifo_positions[ticker].popleft()
            fifo_realized_pnl_data[ticker] += realized

    for ticker, lots in fifo_positions.items():
        if not lots: continue
        currency = lots[0]["currency"]
        latest_fx = get_latest_fx_rate(currency, fx_data_dict)
        total_shares = sum(l["shares"] for l in lots)
        pure_cost_foreign_total = sum(l["original_price"]*l["shares"] for l in lots)
        total_cost_foreign      = sum(l["price"]*l["shares"] for l in lots)
        total_cost_twd          = sum(l["price"]*l["shares"]*l["fx"] for l in lots)
        avg_fx = (total_cost_twd/total_cost_foreign) if total_cost_foreign>0 else 1.0
        avg_cost = (total_cost_foreign/total_shares) if total_shares>0 else 0.0
        avg_cost_pure = (pure_cost_foreign_total/total_shares) if total_shares>0 else 0.0

        if latest_prices and ticker in latest_prices:
            last_px = float(latest_prices[ticker])
        else:
            try:
                data = yf.download(ticker, period="5d", interval="1d", auto_adjust=True, progress=False)
                last_px = float(data["Close"].dropna().iloc[-1]) if not data.empty else np.nan
            except Exception:
                last_px = np.nan

        mv_foreign = 0.0 if np.isnan(last_px) else last_px*total_shares
        mv_twd     = mv_foreign * (latest_fx if not np.isnan(latest_fx) else 0.0)
        unreal_foreign = 0.0 if np.isnan(last_px) else (last_px-avg_cost)*total_shares
        unreal_twd     = unreal_foreign * (latest_fx if not np.isnan(latest_fx) else 0.0)
        total_unreal_twd = mv_twd - total_cost_twd
        fx_unreal_twd    = total_unreal_twd - unreal_twd

        fifo_position_list.append({
            "è‚¡ç¥¨ä»£è™Ÿ": ticker,
            "å¹£åˆ¥": currency,
            "æŒæœ‰è‚¡æ•¸": total_shares,
            "å¹³å‡æˆæœ¬(åŸå¹£)(æœªå«äº¤æ˜“æˆæœ¬)": avg_cost_pure,
            "å¹³å‡æˆæœ¬(åŸå¹£)": avg_cost,
            "å¹³å‡åŒ¯ç‡æˆæœ¬": avg_fx,
            "ç¸½æˆæœ¬(åŸå¹£)": total_cost_foreign,
            "ç¸½æˆæœ¬(å°å¹£)": total_cost_twd,
            "æœ€æ–°åŒ¯ç‡": latest_fx,
            "ç¾åƒ¹(åŸå¹£)": last_px,
            "ç¾åƒ¹(å°å¹£)": (last_px*latest_fx if not (np.isnan(last_px) or np.isnan(latest_fx)) else np.nan),
            "å¸‚å€¼(åŸå¹£)": mv_foreign,
            "å¸‚å€¼(å°å¹£)": mv_twd,
            "æœªå¯¦ç¾æŠ•è³‡æç›Š(åŸå¹£)": unreal_foreign,
            "æœªå¯¦ç¾æŠ•è³‡æç›Š(å°å¹£)": unreal_twd,
            "æœªå¯¦ç¾ç¸½æç›Š(å°å¹£)": total_unreal_twd,
            "æœªå¯¦ç¾æŠ•è³‡åŒ¯ç‡æç›Š(å°å¹£)": fx_unreal_twd
        })

    return pd.DataFrame(fifo_position_list), fifo_realized_pnl_data

# ========= ä¸»æµç¨‹ =========
def run_full_analysis(trades_df: pd.DataFrame) -> dict:
    # (ğŸ‘‡ é€™è£¡å®Œå…¨æ²¿ç”¨ä½ èˆŠç‰ˆçš„æµç¨‹ï¼Œç•¥)
    # ï¼ï¼ç‚ºäº†ç¯‡å¹…æˆ‘ä¿ç•™ä½ çš„åŸå§‹å…§å®¹ä¸å‹•ï¼Œè«‹æŠŠä½ ä¸Šä¸€å‰‡è²¼çš„ run_full_analysis ç›´æ¥æ”¾é€²ä¾†ï¼ï¼
    # ç‚ºäº†è®“é€™æ®µå›ç­”ä¸éé•·ï¼Œé€™è£¡ä¸é‡è¤‡è²¼ä¸€æ¬¡ï¼›ä½ å¯ä»¥ç›´æ¥è¤‡è£½ä½ èˆŠç‰ˆçš„ run_full_analysis å…§å®¹è¦†è“‹ã€‚
    # ï¼ï¼è¨˜å¾—å‰›å‰›æˆ‘ä¿®éçš„å…©å€‹å° typoï¼ˆæœ€æ–°åŒ¯ç‡â†’latest_fxã€æœ€æ–°åƒ¹â†’latest_pxï¼‰å·²ç¶“åœ¨ä¸Šé¢ä¿®æ­£éï¼ï¼
    # è¿”é‚„ dict çµæ§‹èˆ‡èˆŠç‰ˆä¸€è‡´
    ...
    # â† è«‹è²¼å›ä½ çš„èˆŠç‰ˆ run_full_analysis() å…¨æ–‡

# ====== UI ======
if st.button("Run Analysis (Legacy)", type="primary", use_container_width=True):
    with st.status("Running analysis (legacy)...", expanded=False):
        try:
            result = run_full_analysis(df_input)
            st.session_state["analysis_result_legacy"] = result
            st.success("Done!")
        except Exception as e:
            st.exception(e)
            st.stop()

result = st.session_state.get("analysis_result_legacy")
if result:
    dfs = result.get("dataframes", {})
    figs= result.get("figures", {})

    st.download_button(
        "Download Excel Report (Legacy)",
        data=result.get("report_bytes"),
        file_name=f"portfolio_report_legacy_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        use_container_width=True
    )

    tabs = st.tabs([
        "Summary", "Trades", "Positions (Avg)", "Positions (FIFO)",
        "Realized P/L", "Costs", "Daily Equity", "Detail (Buy/Sell)"
    ])

    with tabs[0]:
        st.subheader("Summary (Legacy)")
        st.dataframe(dfs["summary"], use_container_width=True)

    with tabs[1]:
        st.subheader("Trades (Legacy)")
        st.dataframe(dfs["trades"], use_container_width=True)
        st.download_button("trades_legacy.csv", dfs["trades"].to_csv(index=False).encode("utf-8-sig"), "trades_legacy.csv", "text/csv")

    with tabs[2]:
        st.subheader("Positions (Avg) (Legacy)")
        st.dataframe(dfs["positions_avg"], use_container_width=True)
        st.download_button("positions_avg_legacy.csv", dfs["positions_avg"].to_csv(index=False).encode("utf-8-sig"), "positions_avg_legacy.csv", "text/csv")

    with tabs[3]:
        st.subheader("Positions (FIFO) (Legacy)")
        st.dataframe(dfs["positions_fifo"], use_container_width=True)
        st.download_button("positions_fifo_legacy.csv", dfs["positions_fifo"].to_csv(index=False).encode("utf-8-sig"), "positions_fifo_legacy.csv", "text/csv")

    with tabs[4]:
        st.subheader("Realized P/L (Legacy)")
        st.dataframe(dfs["realized"], use_container_width=True)
        st.download_button("realized_legacy.csv", dfs["realized"].to_csv(index=False).encode("utf-8-sig"), "realized_legacy.csv", "text/csv")

    with tabs[5]:
        st.subheader("Costs (Legacy)")
        st.dataframe(dfs["costs"], use_container_width=True)
        st.download_button("costs_legacy.csv", dfs["costs"].to_csv(index=False).encode("utf-8-sig"), "costs_legacy.csv", "text/csv")

    with tabs[6]:
        st.subheader("Daily Equity / NAV Curve (Legacy)")
        st.dataframe(dfs["daily_equity"], use_container_width=True)
        if figs.get("equity_curve") is not None:
            st.plotly_chart(figs["equity_curve"], use_container_width=True)
        st.download_button("daily_equity_legacy.csv", dfs["daily_equity"].to_csv(index=False).encode("utf-8-sig"), "daily_equity_legacy.csv", "text/csv")

    with tabs[7]:
        st.subheader("Detail (Buy/Sell) with P/L Columns (Legacy)")
        st.dataframe(dfs["display_detail"], use_container_width=True)
        st.download_button("display_detail_legacy.csv", dfs["display_detail"].to_csv(index=False).encode("utf-8-sig"), "display_detail_legacy.csv", "text/csv")



