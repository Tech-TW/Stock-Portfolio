# pages/03_üì¶_ÊåÅÂÄâ‰∏äÂÇ≥ÂàÜÊûê.py
import streamlit as st
import pandas as pd
import numpy as np
from io import BytesIO
from datetime import timedelta

import yfinance as yf

st.title("üì¶ ÊåÅÂÄâ‰∏äÂÇ≥ÂàÜÊûêÔºàÁÑ°‰∫§ÊòìÊòéÁ¥∞Ôºâ")

st.markdown(
    """
‰∏äÂÇ≥ÁõÆÂâçÊäïË≥áÁµÑÂêàÊåÅÂÄâÔºåÊ¨Ñ‰ΩçÈúÄÂåÖÂê´Ôºö

- **ËÇ°Á•®‰ª£Ëôü**„ÄÅ**Âπ£Âà•**ÔºàÂèØÁïôÁ©∫ÔºåÊúÉËá™ÂãïÊé®Êñ∑Ôºâ„ÄÅ**ÊåÅÊúâËÇ°Êï∏**„ÄÅ  
- **Âπ≥ÂùáÊàêÊú¨(ÂéüÂπ£)(Êú™Âê´‰∫§ÊòìÊàêÊú¨)**„ÄÅ**Âπ≥ÂùáÊàêÊú¨(ÂéüÂπ£)**„ÄÅ**Âπ≥ÂùáÂåØÁéáÊàêÊú¨**

> Êú¨È†Å‰∏çÈúÄË¶Å‰∫§ÊòìÊòéÁ¥∞ÔºõÊúÉÁõ¥Êé•‰ª•ÊåÅÂÄâÂπ≥ÂùáÊàêÊú¨ÂÅö**Âπ≥ÂùáÊàêÊú¨Ê≥ï**ËàáÔºàÁ≠âÂÉπÂëàÁèæÁöÑÔºâ**FIFO**Â∫´Â≠òË®àÁÆóÔºå‰∏¶ÊäìÊúÄÊñ∞ÂÉπÊ†º/ÂåØÁéáÁî¢ÁîüÂ∏ÇÂÄºËàáÊêçÁõä„ÄÇ
"""
)

# ========== Ëàá‰Ω†‰∏ªÁ®ãÂºè‰∏ÄËá¥ÁöÑËºîÂä© ==========
def determine_currency(ticker: str) -> str:
    t = str(ticker).upper()
    if t.endswith(".TW") or t.endswith(".TWO"):
        return "TWD"
    if t.isdigit() and len(t) == 4:
        return "TWD"
    if t.endswith(".HK"):
        return "HKD"
    if t.endswith(".T"):
        return "JPY"
    if t.endswith(".L"):
        return "GBP"
    if t.endswith(".DE") or t.endswith(".F"):
        return "EUR"
    if t.endswith(".TO"):
        return "CAD"
    if t.endswith(".AX"):
        return "AUD"
    return "USD"

def download_fx_history(currency: str, start_date: pd.Timestamp, end_date: pd.Timestamp) -> pd.DataFrame:
    if currency == "TWD":
        return pd.DataFrame({"Êó•Êúü": [start_date], "ÂåØÁéá": [1.0], "Âπ£Âà•": ["TWD"]})
    try:
        fx_symbol = f"{currency}TWD=X"
        start_ex = start_date - timedelta(days=10)
        end_ex = end_date + timedelta(days=10)
        fx = yf.download(fx_symbol, start=start_ex, end=end_ex, auto_adjust=True, progress=False)
        if fx.empty:
            return pd.DataFrame()
        fx_df = fx["Close"].reset_index()
        fx_df.columns = ["Êó•Êúü", "ÂåØÁéá"]
        fx_df["Êó•Êúü"] = pd.to_datetime(fx_df["Êó•Êúü"]).dt.normalize()
        fx_df["Âπ£Âà•"] = currency
        return fx_df
    except Exception:
        return pd.DataFrame()

def get_latest_fx_rate(currency: str, fx_data_dict: dict) -> float:
    if currency == "TWD":
        return 1.0
    f = fx_data_dict.get(currency)
    if f is None or f.empty:
        try:
            sym = f"{currency}TWD=X"
            fx2 = yf.download(sym, period="5d", interval="1d", auto_adjust=True, progress=False)
            if not fx2.empty:
                return float(fx2["Close"].dropna().iloc[-1])
        except Exception:
            pass
        return np.nan
    f2 = f.dropna(subset=["ÂåØÁéá"]).sort_values("Êó•Êúü", ascending=False)
    if f2.empty:
        return np.nan
    return float(f2.iloc[0]["ÂåØÁéá"])

def download_stock_history(ticker: str, start_date: pd.Timestamp, end_date: pd.Timestamp) -> pd.DataFrame:
    try:
        start_ex = start_date - timedelta(days=10)
        end_ex = end_date + timedelta(days=10)
        s = yf.download(ticker, start=start_ex, end=end_ex, auto_adjust=True, progress=False)
        if s.empty:
            return pd.DataFrame()
        sdf = s["Close"].reset_index()
        sdf.columns = ["Êó•Êúü", "Êî∂Áõ§ÂÉπ"]
        sdf["Êó•Êúü"] = pd.to_datetime(sdf["Êó•Êúü"]).dt.normalize()
        sdf["ËÇ°Á•®‰ª£Ëôü"] = ticker
        return sdf
    except Exception:
        return pd.DataFrame()

# ========== ‰∏äÂÇ≥ÂçÄÔºàËàá Upload È†ÅÁõ∏ÂêåÊ®°ÂºèÔºâ ==========
uploaded_file = st.file_uploader(
    "Upload CSV or Excel",
    type=["csv", "xlsx", "xls"],
    accept_multiple_files=False,
    key="holdings_file_uploader",
)

use_url = st.checkbox("Use URL instead (GitHub raw / cloud link)", key="holdings_use_url")
url_content = None
if use_url:
    url = st.text_input("Paste file URL (e.g., GitHub raw)", key="holdings_url")
    if st.button("Fetch file", use_container_width=True, key="holdings_fetch"):
        try:
            import requests
            r = requests.get(url, timeout=30)
            r.raise_for_status()
            url_content = r.content
            st.success("URL fetched successfully.")
        except Exception as e:
            st.error(f"URL fetch failed: {e}")
            url_content = None

@st.cache_data(show_spinner=False)
def _read_csv(file_or_bytes) -> pd.DataFrame:
    try:
        import chardet
        if isinstance(file_or_bytes, (bytes, bytearray)):
            enc = chardet.detect(file_or_bytes).get("encoding") or "utf-8"
            return pd.read_csv(BytesIO(file_or_bytes), encoding=enc)
        return pd.read_csv(file_or_bytes)
    except Exception:
        if isinstance(file_or_bytes, (bytes, bytearray)):
            return pd.read_csv(BytesIO(file_or_bytes), encoding="utf-8")
        return pd.read_csv(file_or_bytes, encoding="utf-8")

@st.cache_data(show_spinner=False)
def _read_excel(file_or_bytes) -> pd.DataFrame:
    if isinstance(file_or_bytes, (bytes, bytearray)):
        return pd.read_excel(BytesIO(file_or_bytes))
    return pd.read_excel(file_or_bytes)

def _load_df(uploaded_file, url_content):
    if uploaded_file is not None:
        if uploaded_file.name.lower().endswith(".csv"):
            return _read_csv(uploaded_file), uploaded_file.name
        else:
            maybe_df = _read_excel(uploaded_file)
            if isinstance(maybe_df, dict):
                first_key = list(maybe_df.keys())[0]
                return maybe_df[first_key], uploaded_file.name
            return maybe_df, uploaded_file.name
    elif url_content is not None:
        try:
            if "url" in locals() and str(url).lower().endswith(".csv"):
                return _read_csv(url_content), "remote_file.csv"
            try:
                return _read_excel(url_content), "remote_file.xlsx"
            except Exception:
                return _read_csv(url_content), "remote_file.csv"
        except Exception as e:
            st.error(f"Read failed: {e}")
            return None, None
    return None, None

df_holdings, src_name = _load_df(uploaded_file, url_content)

if df_holdings is None:
    st.info("Ë´ã‰∏äÂÇ≥ÁõÆÂâçÊåÅÂÄâË°®„ÄÇ")
    st.stop()

st.success(f"Loaded: {src_name} ({len(df_holdings)} rows)")
st.dataframe(df_holdings.head(50), use_container_width=True)

# ========== Ê¨Ñ‰ΩçÊ™¢Êü•ËàáÊ∏ÖÁêÜ ==========
required_cols = [
    "ËÇ°Á•®‰ª£Ëôü",
    "Âπ£Âà•",
    "ÊåÅÊúâËÇ°Êï∏",
    "Âπ≥ÂùáÊàêÊú¨(ÂéüÂπ£)(Êú™Âê´‰∫§ÊòìÊàêÊú¨)",
    "Âπ≥ÂùáÊàêÊú¨(ÂéüÂπ£)",
    "Âπ≥ÂùáÂåØÁéáÊàêÊú¨",
]

missing = [c for c in required_cols if c not in df_holdings.columns]
if missing:
    st.error(f"Áº∫Â∞ëÂøÖË¶ÅÊ¨Ñ‰ΩçÔºö{missing}")
    st.stop()

df = df_holdings.copy()

# Âπ£Âà•Ëá™ÂãïË£úÊé®Êñ∑
df["Âπ£Âà•"] = df["Âπ£Âà•"].fillna(df["ËÇ°Á•®‰ª£Ëôü"].apply(determine_currency))

# ÂûãÂà•Ê∏ÖÁêÜ
for numcol in ["ÊåÅÊúâËÇ°Êï∏", "Âπ≥ÂùáÊàêÊú¨(ÂéüÂπ£)(Êú™Âê´‰∫§ÊòìÊàêÊú¨)", "Âπ≥ÂùáÊàêÊú¨(ÂéüÂπ£)", "Âπ≥ÂùáÂåØÁéáÊàêÊú¨"]:
    df[numcol] = pd.to_numeric(df[numcol], errors="coerce").fillna(0.0)

# ÂÖÅË®±ÈÅ∏ÊìáÁî®Âê´Êàñ‰∏çÂê´‰∫§ÊòìÊàêÊú¨ÁöÑÂπ≥ÂùáÊàêÊú¨
cost_choice = st.radio(
    "Âπ≥ÂùáÊàêÊú¨‰ΩøÁî®Ôºö",
    ["Âπ≥ÂùáÊàêÊú¨(ÂéüÂπ£)", "Âπ≥ÂùáÊàêÊú¨(ÂéüÂπ£)(Êú™Âê´‰∫§ÊòìÊàêÊú¨)"],
    index=0,
    horizontal=True,
)
cost_col = cost_choice

# ========== ÊäìÂÉπÊäìÂåØ ==========
# Êâæ‰∏ÄÂÄãÈÅ©Áî®ÁöÑÊó•ÊúüÁØÑÂúçÔºàÈÄô‰∏ÄÈ†ÅÂè™Áî®„ÄåÊúÄÊñ∞„ÄçÂç≥ÂèØÔºå‰ΩÜ fx ÊäìË≥áÊñôÈúÄËµ∑Ë®ñÔºâ
today = pd.Timestamp.today(tz="Asia/Taipei").normalize().tz_localize(None)
start_date = today - pd.Timedelta(days=10)
end_date = today

fx_data_dict = {}
currencies = df["Âπ£Âà•"].dropna().unique()
for cur in currencies:
    fx_df = download_fx_history(cur, start_date, end_date)
    if not fx_df.empty:
        fx_data_dict[cur] = fx_df

latest_fx_map = {cur: get_latest_fx_rate(cur, fx_data_dict) for cur in currencies}

latest_px_map = {}
for tkr in df["ËÇ°Á•®‰ª£Ëôü"].dropna().unique():
    try:
        data = yf.download(tkr, period="5d", interval="1d", auto_adjust=True, progress=False)
        latest_px_map[tkr] = float(data["Close"].dropna().iloc[-1]) if not data.empty else np.nan
    except Exception:
        latest_px_map[tkr] = np.nan

# ========== Âπ≥ÂùáÊàêÊú¨Ê≥ïÂ∫´Â≠òË°® ==========
avg_rows = []
for _, r in df.iterrows():
    tkr = str(r["ËÇ°Á•®‰ª£Ëôü"])
    ccy = str(r["Âπ£Âà•"])
    shares = float(r["ÊåÅÊúâËÇ°Êï∏"])
    avg_cost_foreign = float(r[cost_col])            # ‰æùÈÅ∏Êìá‰ΩøÁî®Âê´/‰∏çÂê´‰∫§ÊòìÊàêÊú¨ÁöÑÂπ≥ÂùáÊàêÊú¨
    avg_fx = float(r["Âπ≥ÂùáÂåØÁéáÊàêÊú¨"]) if r["Âπ≥ÂùáÂåØÁéáÊàêÊú¨"] else latest_fx_map.get(ccy, np.nan)

    last_px = latest_px_map.get(tkr, np.nan)
    last_fx = latest_fx_map.get(ccy, np.nan)

    total_cost_foreign = avg_cost_foreign * shares
    total_cost_twd = total_cost_foreign * (avg_fx if not np.isnan(avg_fx) else 0.0)

    mv_foreign = 0.0 if np.isnan(last_px) else last_px * shares
    mv_twd = mv_foreign * (last_fx if not np.isnan(last_fx) else 0.0)

    unreal_invest_foreign = 0.0 if np.isnan(last_px) else (last_px - avg_cost_foreign) * shares
    unreal_invest_twd = unreal_invest_foreign * (last_fx if not np.isnan(last_fx) else 0.0)
    unreal_total_twd = mv_twd - total_cost_twd
    fx_unreal_twd = unreal_total_twd - unreal_invest_twd

    # ‰º∞ÂõûÊú™Âê´‰∫§ÊòìÊàêÊú¨Âπ≥ÂùáÊàêÊú¨ÔºàËã•ÈÅ∏ÁöÑÊòØÂê´‰∫§ÊòìÊàêÊú¨ÔºåÂâáË£ú‰∏ÄÊ¨ÑÔºâ
    avg_cost_pure = float(r["Âπ≥ÂùáÊàêÊú¨(ÂéüÂπ£)(Êú™Âê´‰∫§ÊòìÊàêÊú¨)"])

    avg_rows.append({
        "ËÇ°Á•®‰ª£Ëôü": tkr,
        "Âπ£Âà•": ccy,
        "ÊåÅÊúâËÇ°Êï∏": shares,
        "Âπ≥ÂùáÊàêÊú¨(ÂéüÂπ£)(Êú™Âê´‰∫§ÊòìÊàêÊú¨)": avg_cost_pure,
        "Âπ≥ÂùáÊàêÊú¨(ÂéüÂπ£)": avg_cost_foreign,
        "Âπ≥ÂùáÂåØÁéáÊàêÊú¨": avg_fx,
        "Á∏ΩÊàêÊú¨(ÂéüÂπ£)": total_cost_foreign,
        "Á∏ΩÊàêÊú¨(Âè∞Âπ£)": total_cost_twd,
        "ÊúÄÊñ∞ÂåØÁéá": last_fx,
        "ÁèæÂÉπ(ÂéüÂπ£)": last_px,
        "ÁèæÂÉπ(Âè∞Âπ£)": (last_px * last_fx if not (np.isnan(last_px) or np.isnan(last_fx)) else np.nan),
        "Â∏ÇÂÄº(ÂéüÂπ£)": mv_foreign,
        "Â∏ÇÂÄº(Âè∞Âπ£)": mv_twd,
        "Êú™ÂØ¶ÁèæÊäïË≥áÊêçÁõä(ÂéüÂπ£)": unreal_invest_foreign,
        "Êú™ÂØ¶ÁèæÊäïË≥áÊêçÁõä(Âè∞Âπ£)": unreal_invest_twd,
        "Êú™ÂØ¶ÁèæÁ∏ΩÊêçÁõä(Âè∞Âπ£)": unreal_total_twd,
        "Êú™ÂØ¶ÁèæÊäïË≥áÂåØÁéáÊêçÁõä(Âè∞Âπ£)": fx_unreal_twd,
    })

positions_avg = pd.DataFrame(avg_rows)

st.subheader("üìä Âπ≥ÂùáÊàêÊú¨Ê≥ïÂ∫´Â≠òÊòéÁ¥∞")
st.dataframe(positions_avg, use_container_width=True)

# ========== FIFO Â∫´Â≠òË°®ÔºàÁÑ°Ë≥£Âá∫ ‚Üí ËàáÂπ≥ÂùáÊàêÊú¨ÁµêÊûú‰∏ÄËá¥Ôºõ‰ΩÜ‰øùÁïôÂêåÊ¨Ñ‰ΩçÁµêÊßãÔºâ ==========
positions_fifo = positions_avg.copy()
positions_fifo = positions_fifo[
    [
        "ËÇ°Á•®‰ª£Ëôü", "Âπ£Âà•", "ÊåÅÊúâËÇ°Êï∏",
        "Âπ≥ÂùáÊàêÊú¨(ÂéüÂπ£)(Êú™Âê´‰∫§ÊòìÊàêÊú¨)", "Âπ≥ÂùáÊàêÊú¨(ÂéüÂπ£)", "Âπ≥ÂùáÂåØÁéáÊàêÊú¨",
        "Á∏ΩÊàêÊú¨(ÂéüÂπ£)", "Á∏ΩÊàêÊú¨(Âè∞Âπ£)",
        "ÊúÄÊñ∞ÂåØÁéá", "ÁèæÂÉπ(ÂéüÂπ£)", "ÁèæÂÉπ(Âè∞Âπ£)",
        "Â∏ÇÂÄº(ÂéüÂπ£)", "Â∏ÇÂÄº(Âè∞Âπ£)",
        "Êú™ÂØ¶ÁèæÊäïË≥áÊêçÁõä(ÂéüÂπ£)", "Êú™ÂØ¶ÁèæÊäïË≥áÊêçÁõä(Âè∞Âπ£)",
        "Êú™ÂØ¶ÁèæÁ∏ΩÊêçÁõä(Âè∞Âπ£)", "Êú™ÂØ¶ÁèæÊäïË≥áÂåØÁéáÊêçÁõä(Âè∞Âπ£)",
    ]
].copy()

st.subheader("üìö FIFO Â∫´Â≠òÊòéÁ¥∞ÔºàÂÉÖÊåÅÊúâ„ÄÅÁÑ°Ë≥£Âá∫ ‚Üí ÁµêÊûúËàáÂπ≥ÂùáÊàêÊú¨‰∏ÄËá¥Ôºâ")
st.dataframe(positions_fifo, use_container_width=True)

# ========== Summary ËàáÊØèÊó•Á∏ΩÈ°çÔºà‰ª•‰ªäÊó•ÁÇ∫Âü∫Ê∫ñÔºâ ==========
total_twd_cost = float(positions_avg["Á∏ΩÊàêÊú¨(Âè∞Âπ£)"].sum()) if not positions_avg.empty else 0.0
total_twd_value = float(positions_avg["Â∏ÇÂÄº(Âè∞Âπ£)"].sum()) if not positions_avg.empty else 0.0
total_unreal = float(positions_avg["Êú™ÂØ¶ÁèæÁ∏ΩÊêçÁõä(Âè∞Âπ£)"].sum()) if not positions_avg.empty else 0.0

summary = pd.DataFrame(
    {
        "ÊåáÊ®ô": [
            "Êó•Êúü",
            "Á∏ΩÊäïË≥áÊàêÊú¨(Âè∞Âπ£)",
            "Â∏ÇÂÄº(Âè∞Âπ£)",
            "Êú™ÂØ¶ÁèæÊêçÁõä(Âè∞Âπ£)",
            "Â†±ÈÖ¨Áéá(%)",
        ],
        "ÂÄº": [
            f"{today.date()}",
            round(total_twd_cost, 0),
            round(total_twd_value, 0),
            round(total_unreal, 0),
            round((total_unreal / total_twd_cost * 100.0), 2) if total_twd_cost > 0 else np.nan,
        ],
    }
)

st.subheader("üßæ Summary")
st.dataframe(summary, use_container_width=True)

daily_equity = pd.DataFrame(
    {"Êó•Êúü": [today], "ÊäïÁµÑÁ∏ΩÈ°ç_Êó•Â†±": [round(total_twd_value, 0)]}
)

# ========== ÂèØË¶ñÂåñÔºàÁ∞°ÁâàÔºâ ==========
try:
    import plotly.express as px

    st.subheader("üìà ÊäïÁµÑÁ∏ΩÈ°çÔºà‰ªäÊó•Ôºâ")
    fig = px.line(daily_equity, x="Êó•Êúü", y="ÊäïÁµÑÁ∏ΩÈ°ç_Êó•Â†±", title="ÊäïÁµÑÁ∏ΩÈ°ç-Êó•Â†±Ôºà‰ªäÊó•Ôºâ")
    st.plotly_chart(fig, use_container_width=True)
except Exception:
    pass

# ========== ÂåØÂá∫ Excel ==========
def make_excel_report(dfs: dict) -> bytes:
    buf = BytesIO()
    with pd.ExcelWriter(buf, engine="xlsxwriter") as writer:
        for name, _df in dfs.items():
            safe = str(name)[:31]
            (_df if isinstance(_df, pd.DataFrame) else pd.DataFrame(_df)).to_excel(
                writer, sheet_name=safe, index=False
            )
    buf.seek(0)
    return buf.read()

export_pack = {
    "summary": summary,
    "positions_avg": positions_avg,
    "positions_fifo": positions_fifo,
    "daily_equity": daily_equity,
    "input_holdings": df_holdings,
}

bin_xlsx = make_excel_report(export_pack)
st.download_button(
    "‚¨áÔ∏è ‰∏ãËºâÂ†±Ë°®ÔºàExcelÔºâ",
    data=bin_xlsx,
    file_name="holdings_quick_analysis.xlsx",
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    use_container_width=True,
)
